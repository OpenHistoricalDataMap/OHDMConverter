package ohdm2mapnik;

import ohdm2mapnik.GeoObject.Line;
import ohdm2mapnik.GeoObject.Point;
import ohdm2mapnik.GeoObject.Polygon;
import util.DB;
import util.Parameter;
import util.SQLStatementQueue;

import java.io.IOException;
import java.sql.Connection;
import java.sql.ResultSet;
import java.sql.SQLException;

public class OHDM2MapnikTables {

    // chunk size to import at once
    private static int chunkSize = 10000;

    public static void main(String[] args) throws SQLException, IOException {
        String sourceParameterFileName = "db_ohdm.txt";
        String targetParameterFileName = "db_mapnik.txt";

        if (args.length > 0) {
            sourceParameterFileName = args[0];
        }

        if (args.length > 1) {
            targetParameterFileName = args[1];
        }

        Parameter sourceParameter = new Parameter(sourceParameterFileName);
        Parameter targetParameter = new Parameter(targetParameterFileName);

        Connection connection = DB.createConnection(targetParameter);

        String targetSchema = targetParameter.getSchema();

        String sourceSchema = sourceParameter.getSchema();

        SQLStatementQueue sql = new SQLStatementQueue(connection);
        OHDM2MapnikTables mapnikTables = new OHDM2MapnikTables();

        mapnikTables.setupMapnikDB(sql, targetSchema);
        mapnikTables.setupCacheMapnikTables(sql, sourceSchema);

        mapnikTables.convertDatabase(sql, targetSchema, sourceSchema);

        System.out.println("Mapnik tables creation finished");
    }

    /**
     * create cache tables for the mapnik db
     * @param sql
     * @param sourceSchema
     */
    void setupCacheMapnikTables(SQLStatementQueue sql, String sourceSchema) {

        // points
        sql.append("DROP TABLE IF EXISTS " + sourceSchema + ".tmp_ohdm_points CASCADE; " +
                "CREATE TABLE " + sourceSchema + ".tmp_ohdm_points " +
                "(" +
                "    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY," +
                "    geoobject_id bigint NOT NULL," +
                "    name character varying(255) COLLATE pg_catalog.\"default\"," +
                "    classification_class character varying(255) COLLATE pg_catalog.\"default\"," +
                "    classification_subclassname character varying(255) COLLATE pg_catalog.\"default\"," +
                "    tags hstore," +
                "    valid_since date NOT NULL," +
                "    valid_until date NOT NULL," +
                "    way geometry" +
                ");");

        // lines
        sql.append("DROP TABLE IF EXISTS " + sourceSchema + ".tmp_ohdm_lines CASCADE; " +
                "CREATE TABLE " + sourceSchema + ".tmp_ohdm_lines" +
                "(" +
                "    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY," +
                "    geoobject_id bigint NOT NULL," +
                "    name character varying(255) COLLATE pg_catalog.\"default\"," +
                "    classification_class character varying(255) COLLATE pg_catalog.\"default\"," +
                "    classification_subclassname character varying(255) COLLATE pg_catalog.\"default\"," +
                "    tags hstore," +
                "    valid_since date NOT NULL," +
                "    valid_until date NOT NULL," +
                "    way geometry" +
                ");");

        // polygons
        sql.append("DROP TABLE IF EXISTS " + sourceSchema + ".tmp_ohdm_polygons CASCADE; " +
                "CREATE TABLE " + sourceSchema + ".tmp_ohdm_polygons" +
                "(" +
                "    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY," +
                "    geoobject_id bigint NOT NULL," +
                "    name character varying(255) COLLATE pg_catalog.\"default\"," +
                "    classification_class character varying(255) COLLATE pg_catalog.\"default\"," +
                "    classification_subclassname character varying(255) COLLATE pg_catalog.\"default\"," +
                "    tags hstore," +
                "    valid_since date NOT NULL," +
                "    valid_until date NOT NULL," +
                "    way geometry" +
                ");");


        try {
            sql.forceExecute();
        } catch (SQLException e) {
            System.err.println("exception ignored: " + e);
        }

        System.out.println("Mapnik cache tables created!");
    }

    /**
     * fill cache tables for the mapnik db with ohdm data
     * @param sql
     * @param sourceSchema
     */
    void fillCacheMapnikTables(SQLStatementQueue sql, String sourceSchema) {
        System.out.println("Start to fill the mapnik cache tables, this could take some hours...");

        try {
            sql.forceExecute();
        } catch (SQLException e) {
            System.err.println("exception ignored: " + e);
        }

        // points
        sql.append("INSERT INTO " + sourceSchema + ".tmp_ohdm_points (geoobject_id, name, classification_class, classification_subclassname, tags, valid_since, valid_until, way) " +
                "SELECT " +
                "geoobject_geometry.id_geoobject_source as geoobject_id, " +
                "geoobject.name, " +
                "classification.class as classification_class, " +
                "classification.subclassname as classification_subclassname, " +
                "geoobject_geometry.tags, " +
                "geoobject_geometry.valid_since, " +
                "geoobject_geometry.valid_until, " +
                "points.point as way " +
                "FROM " + sourceSchema + ".points " +
                "INNER JOIN " + sourceSchema + ".geoobject_geometry ON points.id=geoobject_geometry.id_target " +
                "INNER JOIN " + sourceSchema + ".geoobject ON geoobject_geometry.id_geoobject_source=geoobject.id " +
                "INNER JOIN " + sourceSchema + ".classification ON geoobject_geometry.classification_id=classification.id " +
                "WHERE geoobject_geometry.type_target = 0 or geoobject_geometry.type_target = 1;");

        System.out.println("start filling points ...");
        try {
            sql.forceExecute();
        } catch (SQLException e) {
            System.err.println("exception ignored: " + e);
        }

        // lines
        sql.append("INSERT INTO " + sourceSchema + ".tmp_ohdm_lines (geoobject_id, name, classification_class, classification_subclassname, tags, valid_since, valid_until, way) " +
                "SELECT " +
                "geoobject_geometry.id_geoobject_source as geoobject_id, " +
                "geoobject.name, " +
                "classification.class as classification_class, " +
                "classification.subclassname as classification_subclassname, " +
                "geoobject_geometry.tags, " +
                "geoobject_geometry.valid_since, " +
                "geoobject_geometry.valid_until, " +
                "lines.line as way " +
                "FROM " + sourceSchema + ".lines " +
                "INNER JOIN " + sourceSchema + ".geoobject_geometry ON lines.id=geoobject_geometry.id_target " +
                "INNER JOIN " + sourceSchema + ".geoobject ON geoobject_geometry.id_geoobject_source=geoobject.id " +
                "INNER JOIN " + sourceSchema + ".classification ON geoobject_geometry.classification_id=classification.id " +
                "WHERE geoobject_geometry.type_target = 2;");

        System.out.println("start filling lines ...");
        try {
            sql.forceExecute();
        } catch (SQLException e) {
            System.err.println("exception ignored: " + e);
        }

        // polygons
        sql.append("INSERT INTO " + sourceSchema + ".tmp_ohdm_polygons (geoobject_id, name, classification_class, classification_subclassname, tags, valid_since, valid_until, way) " +
                "SELECT " +
                "geoobject_geometry.id_geoobject_source as geoobject_id, " +
                "geoobject.name, " +
                "classification.class as classification_class, " +
                "classification.subclassname as classification_subclassname, " +
                "geoobject_geometry.tags, " +
                "geoobject_geometry.valid_since, " +
                "geoobject_geometry.valid_until, " +
                "polygons.polygon as way " +
                "FROM " + sourceSchema + ".polygons " +
                "INNER JOIN " + sourceSchema + ".geoobject_geometry ON polygons.id=geoobject_geometry.id_target " +
                "INNER JOIN " + sourceSchema + ".geoobject ON geoobject_geometry.id_geoobject_source=geoobject.id " +
                "INNER JOIN " + sourceSchema + ".classification ON geoobject_geometry.classification_id=classification.id " +
                "WHERE geoobject_geometry.type_target = 3;");

        System.out.println("start filling polygons ...");
        try {
            sql.forceExecute();
        } catch (SQLException e) {
            System.err.println("exception ignored: " + e);
        }

        System.out.println("Mapnik cache tables filles!");
    }

    /**
     * delete cache mapnik tables
     * @param sql
     * @param sourceSchema
     */
    void deleteCacheMapnikTables(SQLStatementQueue sql, String sourceSchema) {
        sql.append("DROP TABLE IF EXISTS " + sourceSchema + ".tmp_ohdm_points CASCADE;");
        sql.append("DROP TABLE IF EXISTS " + sourceSchema + ".tmp_ohdm_lines CASCADE;");
        sql.append("DROP TABLE IF EXISTS " + sourceSchema + ".tmp_ohdm_polygons CASCADE;");

        System.out.println("delete cache mapnik tables");
        try {
            sql.forceExecute();
        } catch (SQLException e) {
            System.err.println("exception ignored: " + e);
        }
    }


    /**
     * create mapnik database schema
     * @param sql
     * @param targetSchema
     */
    void setupMapnikDB(SQLStatementQueue sql, String targetSchema) {
        // points
        sql.append("DROP TABLE IF EXISTS " + targetSchema + ".planet_osm_point CASCADE;" +
                "" +
                "CREATE TABLE " + targetSchema + ".planet_osm_point" +
                "(" +
                "    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY," +
                "    osm_id bigint," +
                "    version integer," +
                "    visible boolean," +
                "    geoobject bigint," +
                "    access text COLLATE pg_catalog.\"default\"," +
                "    \"addr:housename\" text COLLATE pg_catalog.\"default\"," +
                "    \"addr:housenumber\" text COLLATE pg_catalog.\"default\"," +
                "    admin_level text COLLATE pg_catalog.\"default\"," +
                "    aerialway text COLLATE pg_catalog.\"default\"," +
                "    aeroway text COLLATE pg_catalog.\"default\"," +
                "    amenity text COLLATE pg_catalog.\"default\"," +
                "    barrier text COLLATE pg_catalog.\"default\"," +
                "    boundary text COLLATE pg_catalog.\"default\"," +
                "    building text COLLATE pg_catalog.\"default\"," +
                "    highway text COLLATE pg_catalog.\"default\"," +
                "    historic text COLLATE pg_catalog.\"default\"," +
                "    junction text COLLATE pg_catalog.\"default\"," +
                "    landuse text COLLATE pg_catalog.\"default\"," +
                "    layer integer," +
                "    leisure text COLLATE pg_catalog.\"default\"," +
                "    lock text COLLATE pg_catalog.\"default\"," +
                "    man_made text COLLATE pg_catalog.\"default\"," +
                "    military text COLLATE pg_catalog.\"default\"," +
                "    name text COLLATE pg_catalog.\"default\"," +
                "    \"natural\" text COLLATE pg_catalog.\"default\"," +
                "    oneway text COLLATE pg_catalog.\"default\"," +
                "    place text COLLATE pg_catalog.\"default\"," +
                "    power text COLLATE pg_catalog.\"default\"," +
                "    railway text COLLATE pg_catalog.\"default\"," +
                "    ref text COLLATE pg_catalog.\"default\"," +
                "    religion text COLLATE pg_catalog.\"default\"," +
                "    shop text COLLATE pg_catalog.\"default\"," +
                "    tourism text COLLATE pg_catalog.\"default\"," +
                "    water text COLLATE pg_catalog.\"default\"," +
                "    waterway text COLLATE pg_catalog.\"default\"," +
                "    tags hstore," +
                "    way geometry(Point,3857)," +
                "    valid_since date," +
                "    valid_until date" +
                ");");

        // lines
        sql.append("DROP TABLE IF EXISTS " + targetSchema + ".planet_osm_line CASCADE;" +
                "" +
                "CREATE TABLE " + targetSchema + ".planet_osm_line" +
                "(" +
                "id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY," +
                "    osm_id bigint," +
                "    version integer," +
                "    visible boolean," +
                "    geoobject bigint," +
                "    access text COLLATE pg_catalog.\"default\"," +
                "    \"addr:housename\" text COLLATE pg_catalog.\"default\"," +
                "    \"addr:housenumber\" text COLLATE pg_catalog.\"default\"," +
                "    \"addr:interpolation\" text COLLATE pg_catalog.\"default\"," +
                "    admin_level text COLLATE pg_catalog.\"default\"," +
                "    aerialway text COLLATE pg_catalog.\"default\"," +
                "    aeroway text COLLATE pg_catalog.\"default\"," +
                "    amenity text COLLATE pg_catalog.\"default\"," +
                "    barrier text COLLATE pg_catalog.\"default\"," +
                "    bicycle text COLLATE pg_catalog.\"default\"," +
                "    bridge text COLLATE pg_catalog.\"default\"," +
                "    boundary text COLLATE pg_catalog.\"default\"," +
                "    building text COLLATE pg_catalog.\"default\"," +
                "    construction text COLLATE pg_catalog.\"default\"," +
                "    covered text COLLATE pg_catalog.\"default\"," +
                "    foot text COLLATE pg_catalog.\"default\"," +
                "    highway text COLLATE pg_catalog.\"default\"," +
                "    historic text COLLATE pg_catalog.\"default\"," +
                "    horse text COLLATE pg_catalog.\"default\"," +
                "    junction text COLLATE pg_catalog.\"default\"," +
                "    landuse text COLLATE pg_catalog.\"default\"," +
                "    layer integer," +
                "    leisure text COLLATE pg_catalog.\"default\"," +
                "    lock text COLLATE pg_catalog.\"default\"," +
                "    man_made text COLLATE pg_catalog.\"default\"," +
                "    military text COLLATE pg_catalog.\"default\"," +
                "    name text COLLATE pg_catalog.\"default\"," +
                "    \"natural\" text COLLATE pg_catalog.\"default\"," +
                "    oneway text COLLATE pg_catalog.\"default\"," +
                "    place text COLLATE pg_catalog.\"default\"," +
                "    power text COLLATE pg_catalog.\"default\"," +
                "    railway text COLLATE pg_catalog.\"default\"," +
                "    ref text COLLATE pg_catalog.\"default\"," +
                "    religion text COLLATE pg_catalog.\"default\"," +
                "    route text COLLATE pg_catalog.\"default\"," +
                "    service text COLLATE pg_catalog.\"default\"," +
                "    shop text COLLATE pg_catalog.\"default\"," +
                "    surface text COLLATE pg_catalog.\"default\"," +
                "    tourism text COLLATE pg_catalog.\"default\"," +
                "    tracktype text COLLATE pg_catalog.\"default\"," +
                "    tunnel text COLLATE pg_catalog.\"default\"," +
                "    water text COLLATE pg_catalog.\"default\"," +
                "    waterway text COLLATE pg_catalog.\"default\"," +
                "    way_area double precision," +
                "    z_order integer," +
                "    tags hstore," +
                "    way geometry(LineString,3857)," +
                "    valid_since date," +
                "    valid_until date" +
                ");");

        // roads
        sql.append("DROP TABLE IF EXISTS " + targetSchema + ".planet_osm_roads CASCADE;" +
                "" +
                "CREATE TABLE " + targetSchema + ".planet_osm_roads" +
                "(" +
                "    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY," +
                "    osm_id bigint," +
                "    version integer," +
                "    visible boolean," +
                "    geoobject bigint," +
                "    access text COLLATE pg_catalog.\"default\"," +
                "    \"addr:housename\" text COLLATE pg_catalog.\"default\"," +
                "    \"addr:housenumber\" text COLLATE pg_catalog.\"default\"," +
                "    \"addr:interpolation\" text COLLATE pg_catalog.\"default\"," +
                "    admin_level text COLLATE pg_catalog.\"default\"," +
                "    aerialway text COLLATE pg_catalog.\"default\"," +
                "    aeroway text COLLATE pg_catalog.\"default\"," +
                "    amenity text COLLATE pg_catalog.\"default\"," +
                "    barrier text COLLATE pg_catalog.\"default\"," +
                "    bicycle text COLLATE pg_catalog.\"default\"," +
                "    bridge text COLLATE pg_catalog.\"default\"," +
                "    boundary text COLLATE pg_catalog.\"default\"," +
                "    building text COLLATE pg_catalog.\"default\"," +
                "    construction text COLLATE pg_catalog.\"default\"," +
                "    covered text COLLATE pg_catalog.\"default\"," +
                "    foot text COLLATE pg_catalog.\"default\"," +
                "    highway text COLLATE pg_catalog.\"default\"," +
                "    historic text COLLATE pg_catalog.\"default\"," +
                "    horse text COLLATE pg_catalog.\"default\"," +
                "    junction text COLLATE pg_catalog.\"default\"," +
                "    landuse text COLLATE pg_catalog.\"default\"," +
                "    layer integer," +
                "    leisure text COLLATE pg_catalog.\"default\"," +
                "    lock text COLLATE pg_catalog.\"default\"," +
                "    man_made text COLLATE pg_catalog.\"default\"," +
                "    military text COLLATE pg_catalog.\"default\"," +
                "    name text COLLATE pg_catalog.\"default\"," +
                "    \"natural\" text COLLATE pg_catalog.\"default\"," +
                "    oneway text COLLATE pg_catalog.\"default\"," +
                "    place text COLLATE pg_catalog.\"default\"," +
                "    power text COLLATE pg_catalog.\"default\"," +
                "    railway text COLLATE pg_catalog.\"default\"," +
                "    ref text COLLATE pg_catalog.\"default\"," +
                "    religion text COLLATE pg_catalog.\"default\"," +
                "    route text COLLATE pg_catalog.\"default\"," +
                "    service text COLLATE pg_catalog.\"default\"," +
                "    shop text COLLATE pg_catalog.\"default\"," +
                "    surface text COLLATE pg_catalog.\"default\"," +
                "    tourism text COLLATE pg_catalog.\"default\"," +
                "    tracktype text COLLATE pg_catalog.\"default\"," +
                "    tunnel text COLLATE pg_catalog.\"default\"," +
                "    water text COLLATE pg_catalog.\"default\"," +
                "    waterway text COLLATE pg_catalog.\"default\"," +
                "    way_area double precision," +
                "    z_order integer," +
                "    tags hstore," +
                "    way geometry(LineString,3857)," +
                "    valid_since date," +
                "    valid_until date" +
                ");");

        // polygons
        sql.append("DROP TABLE IF EXISTS " + targetSchema + ".planet_osm_polygon CASCADE;" +
                "" +
                "CREATE TABLE " + targetSchema + ".planet_osm_polygon" +
                "(" +
                "    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY," +
                "    osm_id bigint," +
                "    version integer," +
                "    visible boolean," +
                "    geoobject bigint," +
                "    access text COLLATE pg_catalog.\"default\"," +
                "    \"addr:housename\" text COLLATE pg_catalog.\"default\"," +
                "    \"addr:housenumber\" text COLLATE pg_catalog.\"default\"," +
                "    \"addr:interpolation\" text COLLATE pg_catalog.\"default\"," +
                "    admin_level text COLLATE pg_catalog.\"default\"," +
                "    aerialway text COLLATE pg_catalog.\"default\"," +
                "    aeroway text COLLATE pg_catalog.\"default\"," +
                "    amenity text COLLATE pg_catalog.\"default\"," +
                "    barrier text COLLATE pg_catalog.\"default\"," +
                "    bicycle text COLLATE pg_catalog.\"default\"," +
                "    bridge text COLLATE pg_catalog.\"default\"," +
                "    boundary text COLLATE pg_catalog.\"default\"," +
                "    building text COLLATE pg_catalog.\"default\"," +
                "    construction text COLLATE pg_catalog.\"default\"," +
                "    covered text COLLATE pg_catalog.\"default\"," +
                "    foot text COLLATE pg_catalog.\"default\"," +
                "    highway text COLLATE pg_catalog.\"default\"," +
                "    historic text COLLATE pg_catalog.\"default\"," +
                "    horse text COLLATE pg_catalog.\"default\"," +
                "    junction text COLLATE pg_catalog.\"default\"," +
                "    landuse text COLLATE pg_catalog.\"default\"," +
                "    layer integer," +
                "    leisure text COLLATE pg_catalog.\"default\"," +
                "    lock text COLLATE pg_catalog.\"default\"," +
                "    man_made text COLLATE pg_catalog.\"default\"," +
                "    military text COLLATE pg_catalog.\"default\"," +
                "    name text COLLATE pg_catalog.\"default\"," +
                "    \"natural\" text COLLATE pg_catalog.\"default\"," +
                "    oneway text COLLATE pg_catalog.\"default\"," +
                "    place text COLLATE pg_catalog.\"default\"," +
                "    power text COLLATE pg_catalog.\"default\"," +
                "    railway text COLLATE pg_catalog.\"default\"," +
                "    ref text COLLATE pg_catalog.\"default\"," +
                "    religion text COLLATE pg_catalog.\"default\"," +
                "    route text COLLATE pg_catalog.\"default\"," +
                "    service text COLLATE pg_catalog.\"default\"," +
                "    shop text COLLATE pg_catalog.\"default\"," +
                "    surface text COLLATE pg_catalog.\"default\"," +
                "    tourism text COLLATE pg_catalog.\"default\"," +
                "    tracktype text COLLATE pg_catalog.\"default\"," +
                "    tunnel text COLLATE pg_catalog.\"default\"," +
                "    water text COLLATE pg_catalog.\"default\"," +
                "    waterway text COLLATE pg_catalog.\"default\"," +
                "    way_area double precision," +
                "    z_order integer," +
                "    tags hstore," +
                "    way geometry(Geometry,3857)," +
                "    valid_since date," +
                "    valid_until date" +
                ")");

        try {
            sql.forceExecute();
        } catch (SQLException e) {
            System.err.println("exception ignored: " + e);
        }

        System.out.println("Mapnik tables created!");
    }

    /**
     * Count rows to convert
     * @param sql
     * @param sourceSchema
     * @param table which should be counted
     * @return
     * @throws SQLException
     */
    private int countRows(SQLStatementQueue sql, String sourceSchema, String table) throws SQLException {
        sql.append("SELECT COUNT(*) FROM " + sourceSchema + "." + table + ";");


        ResultSet result = null;
        try {
            result = sql.executeWithResult();
        } catch (SQLException e) {
            System.err.println("exception ignored: " + e);
        }

        while (result.next()) {
            return result.getInt(1); // counted rows
        }

        return 0;
    }

    /**
     * Show the current import status
     *
     * @param currentRow
     * @param maxRow
     * @param geometry
     */
    void showImportStatus(int currentRow, int maxRow, String geometry) {
        if (currentRow % 10000 == 0) {
            System.out.println(geometry + ": " + currentRow + " of " + maxRow);
        }
    }

    void convertDatabase(SQLStatementQueue sql, String targetSchema, String sourceSchema) throws SQLException {
        // fill cache tables with ohdm data
        this.fillCacheMapnikTables(sql, sourceSchema);

        // count rows
        System.out.println("Count points rows ...");
        int pointsRows = this.countRows(sql, sourceSchema, "tmp_ohdm_points");
        System.out.println("Count lines rows ...");
        int linesRows = this.countRows(sql, sourceSchema, "tmp_ohdm_lines");
        System.out.println("Count polygons rows ...");
        int polygonsRows = this.countRows(sql, sourceSchema, "tmp_ohdm_polygons");

        // start import
        this.convertPoints(sql, targetSchema, sourceSchema, pointsRows);
        this.convertLines(sql, targetSchema, sourceSchema, linesRows);
        this.convertPolygons(sql, targetSchema, sourceSchema, polygonsRows);

        // delete cache tables
        this.deleteCacheMapnikTables(sql, sourceSchema);
    }


    /**
     * Convert point cache mapnik tables to real mapnik tables
     * @param sql
     * @param targetSchema
     * @param sourceSchema
     * @param maxRows
     * @throws SQLException
     */
    void convertPoints(SQLStatementQueue sql, String targetSchema, String sourceSchema, int maxRows) throws SQLException {
        System.out.println("Start import points!");

        for (int i = 0; i <= maxRows; i += this.chunkSize) {
            sql.append("SELECT id, geoobject_id, name, classification_class, classification_subclassname, tags, valid_since, valid_until, ST_TRANSFORM(way, 3857) as way " +
                    "FROM " + sourceSchema + ".tmp_ohdm_points "+
                    "ORDER BY id LIMIT " + this.chunkSize + " OFFSET " + i + ";");
            ResultSet result = null;
            try {
                result = sql.executeWithResult();
            } catch (SQLException e) {
                System.err.println("exception ignored: " + e);
            }

            Point point;
            int currentRow = i;

            while (result.next()) {
                point = new Point(
                        result.getLong(1), // id
                        result.getLong(2), // geoobjectId
                        result.getString(3), // name
                        result.getString(4), // classificationClass
                        result.getString(5), // classificationSubclassname
                        result.getString(6), // tags
                        result.getDate(7), // validSince
                        result.getDate(8), // validUntil
                        result.getString(9) // way
                );

                sql.append(point.getMapnikQuery(targetSchema));

                currentRow++;
                this.showImportStatus(currentRow, maxRows, "point");
            }

            System.out.println("Upload to database...");
            try {
                sql.forceExecute();
            } catch (SQLException e) {
                System.err.println("exception ignored: " + e);
            }
        }
        System.out.println("Points import are completed!");
    }

    /**
     * Convert line cache mapnik tables to real mapnik tables
     * @param sql
     * @param targetSchema
     * @param sourceSchema
     * @param maxRows
     * @throws SQLException
     */
    void convertLines(SQLStatementQueue sql, String targetSchema, String sourceSchema, int maxRows) throws SQLException {
        System.out.println("Start import lines!");

        for (int i = 0; i <= maxRows; i += this.chunkSize) {
            sql.append("SELECT id, geoobject_id, name, classification_class, classification_subclassname, tags, valid_since, valid_until, ST_TRANSFORM(way, 3857) as way " +
                    "FROM " + sourceSchema + ".tmp_ohdm_lines "+
                    "ORDER BY id LIMIT " + this.chunkSize + " OFFSET " + i + ";");

            ResultSet result = null;
            try {
                result = sql.executeWithResult();
            } catch (SQLException e) {
                System.err.println("exception ignored: " + e);
            }

            Line line;
            int currentRow = i;

            while (result.next()) {
                line = new Line(
                        result.getLong(1), // id
                        result.getLong(2), // geoobjectId
                        result.getString(3), // name
                        result.getString(4), // classificationClass
                        result.getString(5), // classificationSubclassname
                        result.getString(6), // tags
                        result.getDate(7), // validSince
                        result.getDate(8), // validUntil
                        result.getString(9) // way
                );

                sql.append(line.getMapnikQuery(targetSchema));

                currentRow++;
                this.showImportStatus(currentRow, maxRows, "line");
            }

            System.out.println("Upload to database...");
            try {
                sql.forceExecute();
            } catch (SQLException e) {
                System.err.println("exception ignored: " + e);
            }
        }

        System.out.println("Lines import are completed!");
    }

    /**
     * Convert point cache mapnik tables to real mapnik tables
     * @param sql
     * @param targetSchema
     * @param sourceSchema
     * @param maxRows
     * @throws SQLException
     */
    void convertPolygons(SQLStatementQueue sql, String targetSchema, String sourceSchema, int maxRows) throws SQLException {
        System.out.println("Start import polygons!");

        for (int i = 0; i <= maxRows; i += this.chunkSize) {
            sql.append("SELECT id, geoobject_id, name, classification_class, classification_subclassname, tags, valid_since, valid_until, ST_TRANSFORM(way, 3857) as way " +
                    "FROM " + sourceSchema + ".tmp_ohdm_polygons "+
                    "ORDER BY id LIMIT " + this.chunkSize + " OFFSET " + i + ";");

            ResultSet result = null;
            try {
                result = sql.executeWithResult();
            } catch (SQLException e) {
                System.err.println("exception ignored: " + e);
            }

            Polygon polygon;
            int currentRow = i;

            while (result.next()) {
                polygon = new Polygon(
                        result.getLong(1), // id
                        result.getLong(2), // geoobjectId
                        result.getString(3), // name
                        result.getString(4), // classificationClass
                        result.getString(5), // classificationSubclassname
                        result.getString(6), // tags
                        result.getDate(7), // validSince
                        result.getDate(8), // validUntil
                        result.getString(9) // way
                );

                sql.append(polygon.getMapnikQuery(targetSchema));

                currentRow++;
                this.showImportStatus(currentRow, maxRows, "polygon");
            }

            System.out.println("Upload to database...");
            try {
                sql.forceExecute();
            } catch (SQLException e) {
                System.err.println("exception ignored: " + e);
            }
        }


        // repair polygons
        sql.append("UPDATE " + targetSchema + ".planet_osm_polygon SET way = ST_MakeValid(way) WHERE not ST_IsValid(way);");
        try {
            sql.forceExecute();
        } catch (SQLException e) {
            System.err.println("exception ignored: " + e);
        }

        // set area
        sql.append("UPDATE " + targetSchema + ".planet_osm_polygon SET way_area = ST_Area(way);");
        try {
            sql.forceExecute();
        } catch (SQLException e) {
            System.err.println("exception ignored: " + e);
        }

        System.out.println("Polygons import are completed!");
    }

}
